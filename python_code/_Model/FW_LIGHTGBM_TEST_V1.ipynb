{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE',\n",
    "    'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
    "    'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "    'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG',\n",
    "    'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG',\n",
    "    'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG',\n",
    "    'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n",
    "    'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE',\n",
    "    'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE',\n",
    "    'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI',\n",
    "    'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI',\n",
    "    'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI',\n",
    "    'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE',\n",
    "    'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
    "    'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "    'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n",
    "    'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13',\n",
    "    'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "    'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "    'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK'\n",
    "]\n",
    "application_train = pd.read_csv('../../../../homecredit/application_train.csv')\n",
    "# application_test = pd.read_csv('../../../../homecredit/application_test.csv')\n",
    "\n",
    "application_train= application_train.drop(columns=columns_to_drop)\n",
    "# application_test= application_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1273\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 138\n",
      "[LightGBM] [Info] Start training from score 0.080794\n",
      "cpu version elapse time: 0.9898197650909424\n",
      "*****************************\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1273\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 138\n",
      "[LightGBM] [Info] Using GPU Device: Quadro P600, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 24 dense feature groups (5.63 MB) transferred to GPU in 0.010986 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.080794\n",
      "gpu version elapse time: 5.1506054401397705\n"
     ]
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(application_train.drop('TARGET',axis=1), columns=['NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE'], drop_first=True)\n",
    "\n",
    "\n",
    "X= X_encoded.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "y = application_train.TARGET\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "            'max_bin': 63,\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.1,\n",
    "          'tree_learner': 'serial',\n",
    "          'task': 'train',\n",
    "          'is_training_metric': 'false',\n",
    "          'min_data_in_leaf': 1,\n",
    "          'min_sum_hessian_in_leaf': 100,\n",
    "          'ndcg_eval_at': [1, 3, 5, 10],\n",
    "          'device_type': 'cpu'\n",
    "          }\n",
    "print(\"*****************************\")\n",
    "t0 = time.time()\n",
    "gbm = lgb.train(params, train_set=train_data, num_boost_round=10,\n",
    "                valid_sets=None, valid_names=None, feval=None, init_model=None,\n",
    "                feature_name='auto', categorical_feature='auto',\n",
    "\n",
    "    \n",
    "                keep_training_booster=False, callbacks=None)\n",
    "t1 = time.time()\n",
    "\n",
    "print('cpu version elapse time: {}'.format(t1-t0))\n",
    "time.sleep(20)\n",
    "print(\"*****************************\")\n",
    "\n",
    "params = {\n",
    "    'max_bin': 63,\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.1,\n",
    "          'tree_learner': 'serial',\n",
    "          'task': 'train',\n",
    "          'is_training_metric': 'false',\n",
    "          'min_data_in_leaf': 1,\n",
    "          'min_sum_hessian_in_leaf': 100,\n",
    "          'ndcg_eval_at': [1, 3, 5, 10],\n",
    "          'device_type': 'gpu'\n",
    "          }\n",
    "\n",
    "t0 = time.time()\n",
    "gbm = lgb.train(params, train_set=train_data, num_boost_round=10,\n",
    "                valid_sets=None, valid_names=None, feval=None, init_model=None,\n",
    "                feature_name='auto', categorical_feature='auto',\n",
    "    \n",
    "     \n",
    "                keep_training_booster=False, callbacks=None)\n",
    "t1 = time.time()\n",
    "\n",
    "print('gpu version elapse time: {}'.format(t1-t0))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "\n",
    "y_pred = gbm.predict(X_test)  # 使用已經訓練好的模型對測試數據進行預測\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred.round())  # 分類問題的精確度\n",
    "auc = roc_auc_score(y_test, y_pred)  # 二分類問題的 AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=10000000, n_features=100, n_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3751475, number of negative: 3748525\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 7500000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: Quadro P600, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (715.26 MB) transferred to GPU in 0.653109 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500197 -> initscore=0.000787\n",
      "[LightGBM] [Info] Start training from score 0.000787\n",
      "gpu version elapse time: 56.258347511291504\n",
      "[LightGBM] [Info] Number of positive: 3751475, number of negative: 3748525\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.927415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 7500000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500197 -> initscore=0.000787\n",
      "[LightGBM] [Info] Start training from score 0.000787\n",
      "cpu version elapse time: 75.65107321739197\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model = lgbm.LGBMClassifier(device=\"gpu\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print('gpu version elapse time: {}'.format(t1-t0))\n",
    "\n",
    "t0 = time.time()\n",
    "model = lgbm.LGBMClassifier(device=\"cpu\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print('cpu version elapse time: {}'.format(t1-t0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
